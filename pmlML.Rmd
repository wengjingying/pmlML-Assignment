Practical Machine Learning Assignment

==============================================

```{r echo = F, results='hide'}
Sys.setlocale(category = "LC_ALL", locale = "English_United States.1252")
```

## Background

<br>

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

<br>

## Project Abstract:

<br>

The goal of this project is to predict the manner in which they did the exercise using any of the other variables. This is the "classe" variable in the training set. A report is created describing how the model is built, cross validation, what is the expected out of sample error, and the choice is made. The prediction model is also used to predict 20 different test cases.

<br>

## About "classe"" variables

exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E)


### 1. Obtain datasets and preprocess
```{r}
setwd("F:/Mooc/Data Science/8 Machine Learning/w4")

download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "./pml-training.csv")
download.file("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile = "./pml-testing.csv")

trainingData <- read.csv("pml-training.csv", stringsAsFactors=F, na.string = c("", "NA", "Null"))
testingData <- read.csv("pml-testing.csv", stringsAsFactors=F, na.string = c("", "NA", "Null"))

trainingData$classe<-as.factor(trainingData$classe)
dim(trainingData)
dim(testingData)
```
* Training data has 159 variables, which is too many, we need to narrow down the variables for prediction.

<br>

### 2. Problems in the data - Too many NAs

<br>

Count every columns' with NA
```{r}
NAcount<-function(l){sum(is.na(trainingData[,l]))}
NAC<-sapply(c(1:160),function(x)NAcount(x))
noNA<-sum(NAC==0)
firstNA<-which(NAC>0)[1]
```
There are only `r noNA` columns without NAs,begins at column `r firstNA`.

Omit those columns.
```{r}
train1<-trainingData[, -which(NAC>0)]
```

### 3. Preprocess

* Also remove unrelevant variables like username, timestamp(testing is not based on time serials)
```{r}
remove = c("X", 'user_name', 'raw_timestamp_part_1', 'raw_timestamp_part_2', 'cvtd_timestamp', 'new_window', 'num_window')
train1<-train1[,-which(names(train1) %in% remove)]
```

* Separate training set for cross validation:
```{r}
library(caret)
inTrain<-createDataPartition(y=train1$classe,p=0.7,list=F)
training<-train1[inTrain,]
Validating<-train1[-inTrain,]
```

<br>

* Look at the correlation between variables:
```{r}
M <-abs(cor(training[,-53]))
diag(M)<-0
Cor <-which(M>0.8, arr.ind=T)
NumCor <- length(unique(Cor[,2]))
```

* There are `r NumCor` variables highly correlated. We should pre-process data using PCA (Principle component analysis).

### 4.1 First Model fit using caret library, rpart method.
```{r}
set.seed(12345)
modFitRP<-train(classe~ .,method="rpart",data=training,preProcess="pca")
print(modFitRP$finalModel)
```
* We can see the problem is there is no prediction rules for Classe B & C.

### 4.2 Second Model fit using random forest method.
```{r, fig.width=8}
require(randomForest)
set.seed(12345)
modFitRF=randomForest(classe~.,data=training,ntree=100, importance=TRUE, preProcess="pca")
modFitRF
varImpPlot(modFitRF,)
```

* We can see random forest predicted all five classes, used 7 variables. The OOB estimate of error rate is low. From the variable importance plot, we can see top 7 variables important and been used in the prediction.

<br>

### 5. Evaluate Rpart and Random Forest prediction results on Validating Data.
* Rpart
```{r}
RpartPred = predict(modFitRP, Validating)
predMatrix1 = with(Validating, table(RpartPred, classe))
a1<-sum(diag(predMatrix1))/sum(as.vector(predMatrix1))
a1
```
* The `r a1` accuracy is very low for Rpart method from caret package. 
* Out of sample error  = `r 1-a1`

<br>

* Random Forest
```{r}
RFpred = predict(modFitRF, Validating)
predMatrix2 = with(Validating, table(RFpred, classe))
a2<-sum(diag(predMatrix2))/sum(as.vector(predMatrix2))
a2
```
* Apparantly, Random Forest have much higher and good accuracy `r a2` than Rpart.
* Out of sample error = `r 1-a2`

<br>

### 6. Predict Testing Data

* Now we can use our random forest model to predict 20 observation in testing data.
```{r}
predTest <- predict(modFitRF, testingData)
predTest
```



